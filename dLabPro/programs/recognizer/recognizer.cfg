## dLabPro program recognizer (dLabPro recognizer)
## - Main program
##
## AUTHOR : Frank Duckhorn
## PACKAGE: dLabPro/programs
## 
## Copyright 2013 dLabPro contributors and others (see COPYRIGHT file) 
## - Chair of System Theory and Speech Technology, TU Dresden
## - Chair of Communications Engineering, BTU Cottbus
## 
## This file is part of dLabPro.
## 
## dLabPro is free software: you can redistribute it and/or modify it under the
## terms of the GNU Lesser General Public License as published by the Free
## Software Foundation, either version 3 of the License, or (at your option)
## any later version.
## 
## dLabPro is distributed in the hope that it will be useful, but WITHOUT ANY
## WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
## FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
## details.
## 
## You should have received a copy of the GNU Lesser General Public License
## along with dLabPro. If not, see <http://www.gnu.org/licenses/>.
# Recognizer config file
#
# This file (recognizer.cfg) contains default values
# for all options and is compiled in the program.
# If you want to change some options you may write
# an own configuration file with the options to change
# and execute "recognizer -cfg FILE.cfg". Or you may
# change options by command line arguments.
# For example run: "recognizer -output dbg".
# "recognizer -h" will give a short help.

# Print short help.
# Shortcut: -h 

# List all options and exit.
# Shortcut: -opts 

# Output configuration
#
# This option defines what the recognizer outputs.
# Possible values are:
#  res   output only one result per line
#  cmd   recognized commands and summary
#  sta   status information of recognition progress
#  dbg   more detailed information about the progress
#  gui   client mode: output information usable for GUI's (energy + vad state for every frame)
#  vad   information about vad progress for every frame
output = sta
# Shortcut: -out X
# [online-able]

# Input configuration
#
# Configures whether something is read from stdin.
# Possible values are:
#  none   Nothing is read.
#  cmd    Read commands from stdin. (only in online mode!)
#         Every line is one command.
#         Possible commands are:
#           "set OPTION VALUE"
#             Online set the option OPTION to VALUE.
#             Only possible for onlineable options
#             (see tag [online-able] here in config).
#           "exit"
#             Quit recognizer
#  fea    Read features from stdin.
#         Every new line marks a new segment for recognition.
#         A line starting with 'l' is interpreted as label of the segment.
#         The features are only modificated by PCA!
input = cmd
# Shortcut: -in X

# Cache enabled
#
# This option enables the cache for grammar compiling.
cache = yes
# [online-able]

# Use a system command to analyze the recognized fst
#
# It is executed with the following arguments:
#  - Temporary filename of the recognized fst
#  - Temporary filename of the reference recognized fst
#  - Temporary filename of the nld-matrix
#  - Temporary filename of the audio signal
#  - Filename of the session info object
postproc.cmd = 

# Search configuration
#
# Search algorithm
#  tp    Token passing
#  as    A* search 
search.typ = tp

# Rejection method
#  off   Rejection disabled
#  phn   Free phoneme reference recognition
#  two   Decode two best paths
search.rej = phn

# Debug level for search algorithm
search.debug = 0

# Should we search while speaking
search.iterative = yes

# Should we prune the search?
search.prn = no

# Pruning configuration
#
# Only usefull if search.prn = yes !
# See dokumentation of fstsearch -as2_param for details.
#  tpprnw   sets weight pruning for token passing (see fstsearch.tp_prnw)
#  tpprnh   sets hypothesis pruning for token passing (see fstsearch.tp_prnh)
#  asprn1   sets FramePruneThr for first search
#  asprn2   sets FramePruneThr for reference search
#  as2prn   sets FramePruneThr for two path search
search.tpprnw = 100
search.tpprnh = 0
search.asprn1 = 40
search.asprn2 = 40
search.as2prn = 110

# Configuration of search rejection
#
#  astna  sets N_TNA for one path A* search
#  as2tna sets N_TNA for two path search
#  as2tne sets N_TNE for two path search
search.astna  = 0.5
search.twotna = 15
search.twotne = 0

# Number of threads to use
#
# only used in token passing search (see fstsearch.tp_threads)
search.threads = 1

# Permanent decoding (without VAD)
#
# Only valid for iterative search.
# Disables VAD!
search.permanent = no

# Force vad decission or selected fst
#
# If you use one of these two options, you have to
# generate for every file "XX.wav" a file "XX.wav.vadforce".
# The binary file should contain a unsigned Byte for every
# frame. The value of the Byte is interpreted so:
#  0   vad off = no speech signal
#  >0  vad on for vad.force and
#      the number of the fst to use for fst.force
# For fst.force you should have multiple units in
# itRN in the session info object.
fst.force = no
vad.force = no

# Set selected fst
#
# Sets the current fst unit within itRN to use for decoding.
# May be used to set initial unit when using data.dialog option
# or for implementing an external dialog manager.
fst.sel = 0
# [online-able]

# Set sleep timeout
#
# Sets the sleep timeout in seconds for fallback
# to sleep vocabulary in dialog. To use this you
# should have at least one transition labeled with
# __SLEEP__ in data.dialog.
fst.sleep = 0

# VAD configuration
#
# vad.minsp  defines the minimal number of frames to use
#            for recognition.
# vad.maxsp  defines the maximal number of frames to use
#            for recognition.
# vad.sigmin defines the minimal signal peak with a speech
#            segment to use it for recognition.
# If vad.nolimit is set to yes, then the options will be
# changed in the following way:
#   vad.minsp  = 0
#   vad.maxsp  = 6000 # this is one minute
#   vad.sigmin = 0
vad.minsp = 40
vad.maxsp = 600
vad.sigmin = 3267
vad.nolimit = no

# Noise reduction (simple algorithm!)
noise_reduce = no

# Noise reduction buffer size
noise_reduce.len = 300

# Noise reduction buffer use percentage
noise_reduce.prc = 0.3

# Meassure time of recognition algorithms (analyse, density, search)
measure_time = yes

# For online recogition define the audio device for
# portaudio. -1 is the default device.
# See "recognizer -l" for other device numbers.
audio.dev = -1
# Shortcut: -d X

# List all audio devices of portaudio and exit.
audio.dev_list = no
# Shortcut: -l 

# Use binary data file
#
# Currently not implemented!
data.bin = 

# Skip NLD calculation and use precalculated ones
#
# Only for binary data file!
skipnld = no

# Forced recognition
#
# The FST in reco_force_rn.fst in the current directory
# is used for search.
force = no

# Sample rate
sig.sample_rate = 16000

# Select signal channel
#
# For multichannel files select that channel for signal extraction.
# (zero-based index)
sig.sel_channel = 0

# Feature info object
#
# File name of the feature info object generated by
# "HMM.xtp trn" in the model directory.
# The object should contain the following fields:
#  idDlt   data    delta table
#  idDltW  data    delta weights
#  idX     data    normalization vector
#  idW     data    PCA matrix
# [online-able]
data.feainfo = $UASR_HOME/data/vm/VM_one2_evo4/model/feainfo.object

# Session info object
#
# File name of the session info object.
# It can be created with the script uasr/scripts/dlabpro/tools/REC_PACKDATA.xtp
# The object should contain the following fields:
#  itRN    fst     recognition network
#  itRNr   fst     reference recognition network
#  itGP    fst     graphem to phonem transducer
#  idLMtos data    output symbol table of itRN
# If you want to use fst.force you have to modify the
# object so that itRN has multiple units with different
# recognition networks.
# [online-able]
data.sesinfo = $UASR_HOME/data/vm/VM_one2_evo4/log/samurai-4BCD8B62-DB006BB4-3_20_mix_subvoc.si

# Gaussian mixture model
#
# File name of the Gaussian mixture model in single precision floating point.
# It can be created with the skript uasr/scripts/dlabpro/tools/REC_PACKDATA.xtp
# [online-able]
data.gmm = $UASR_HOME/data/vm/VM_one2_evo4/model/3_20_mix_samurai_0_force_7_0.floatgm

# VAD info object
#
# File name of the VAD info object.
# The object should contain the following fields:
#  idX     data    normalization vector for VAD (from feainfo.object)
#  idW     data    PCA matrix for VAD (from feainfo.object)
#  itGm    gmm     Gaussian mixture model for VAD (generated from HMM)
#
#      dlabpro vad_create.xtp feainfo.object XXX.floatgm XXX.vad
#
######## vad_create.xtp ###########
## object iFea;
## gmm    iGm;
## object iVAD;
## data   iVAD.idX;
## data   iVAD.idW;
## gmm    iVAD.itGm;
##
## "$1" iFea -restore;
## "$2"    iGm  -restore;
##
## iFea.idX iVAD.idX  =;
## iFea.idW iVAD.idW  =;
## iGm      iVAD.itGm =;
##
## "$3" iVAD /zip -save;
###################################
data.vadinfo = $UASR_HOME/data/vm/VM_vad_10/model/3_10_mod.vad

# Dialog FSA
#
# File name of the dialog finite state acceptor.
# Each state corresponds to the unit in the recognition
# network itRN. The initial dialog state can be defined
# by fst.sel. If an input symbol in the dialog matches
# an accepted recognition result the dialog switches the
# used vocabulary (= unit in itRN).
data.dialog = 
